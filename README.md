# Project-3---Data-Engineering-and-Visualization
## Table of Contents
- [Overview and Purpose](#Overview-and-Purpose)
- [Introduction](#Introduction)
- [Tools](#Tools)
- [Key Steps](#key-steps)
- [Ethical Considerations](#Ethical-Considerations)
- [References for the Data](#References-for-the-Data)
- [References for Codes](#References-for-Codes)

## Overview and purpose

As a group, we decided to pursue the data engineering method to complete this project. We felt more confident in our abilities to complete and thrive in each aspect of the data engineering pathway, while collectively deciding practicing and reviewing the ETL process was more applicable and realistic for the preliminary and introductory durations of a career as a data analyst or engineer. We wanted to strengthen our capabilities in executing the multitude of processes required to extract, transform, and load numerous different forms of data into more readable and explanatory systems. 

As we were looking for a dataset capable of fulfilling all the external requirements from the project rubric, and our own internal requirements, we were able to find a suitable dataset on Kaggle that outlined Amazon transactional data from April through June of 2022 broken down from each state of India. Our purpose was to take the initial CSV file and manipulate it into more descriptive, beneficial, and concise tables to be able to upload into SQL for future queries and the conception of an entity relationship diagram. We incorporated a JSON API into our Jupyter Notebook outlining data with which we feel adds to the analytical foundations of the project. We decided to create, mainly for our benefit, a heatmap using our foundational knowledge in Java and the Leaflet library and the data from our imported API, outlining the relative size of each distinct state in India based on the number of orders detailed during the timeframe in our dataset. In addition, we have included some predictive analysis using the StatsModel library that, with some notable limitations, we hope can predict the trend of sales in the forthcoming months, along with the relational parameters between the different states within the country. 

We hope to have presented our information, including the Jupyter Notebook, outputted CSV files, SQL schema, and Leaflet web app in a way that conveys and presents the analysis directly. We aim to attain each one of the parameters described in the project including the database design, data and delivery, and this GitHub Read Me to the presented standards. 



## Introduction


## Tools


## Key Steps
1. Database Design

2. Data and Delivery

3. Leaflet

## Ethical considerations

After recently being introduced to the ethical side of data, and some examples of where people's personal information may have been distributed inappropriately, we did not want to bridge to a point where we may have been reappropriating information unethically. Our data set does not contain information that we consider too personal or approaching a point where our project could be regarded as unethical. The information characterized in the dataset does not reach a level where a third party could derive any personal information, as the information leading down that path remains inaccessible. The Order ID and Fulfillment columns could potentially be the sources, ethically, where some information could potentially be released without the direct consent of either the individual ordering the item or the merchant who sells the item. Amazon, the company that releases the data, decided to remove all the direct characteristics that could be used detrimentally toward any person who shops on the website. All the other information left represented in the dataset does not give anyone the ability to discern a personâ€™s identity or place of residence. If Amazon were to have not removed the information from the public data any company or anyone could use the included material to potentially harm a person, manufacturer, or wholesaler.  We think that this practice is critically necessary in our modern society where innocent people are abused through data leaks frequently at no fault of their own. Keeping important information private should be paramount for small and large corporations as technological knowledge is at an all-time high. We feel like we have not tangibly entered a place where there is any potential malice of any kind for anyone. 


## References for the data

## References for codes
